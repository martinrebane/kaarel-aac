{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "WORD = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\", include_lengths=True)\n",
    "UD_TAG = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\", pad_token=None, unk_token=None)\n",
    "\n",
    "CHAR_NESTING = data.Field(tokenize=list, init_token=\"<bos>\", eos_token=\"<eos>\")\n",
    "CHAR = data.NestedField(CHAR_NESTING, init_token=\"<bos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # self.hidden = self.init_hidden()\n",
    "\n",
    "    # def init_hidden(self, batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        # return (torch.zeros(1, batch_size, self.hidden_dim),\n",
    "        #         torch.zeros(1, batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # print(embeds.shape)\n",
    "        lstm_out, self.hidden = self.lstm(embeds)\n",
    "        # print(lstm_out.shape)\n",
    "        tag_space = self.hidden2tag(lstm_out)\n",
    "        # print(tag_space.shape)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading en-ud-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:   0%|          | 0.00/688k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:   5%|▍         | 32.8k/688k [00:00<00:02, 284kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:   7%|▋         | 49.2k/688k [00:00<00:02, 225kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:  14%|█▍        | 98.3k/688k [00:00<00:02, 261kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:  29%|██▊       | 197k/688k [00:00<00:01, 329kB/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:  55%|█████▍    | 377k/688k [00:00<00:00, 425kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip:  81%|████████  | 557k/688k [00:00<00:00, 548kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\ren-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 959kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_data, valid_data, test_data = datasets.UDPOS.splits(\n",
    "    fields=(('word', WORD), ('udtag', UD_TAG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': <torchtext.data.field.Field object at 0x7f4ac02fda90>, 'udtag': <torchtext.data.field.Field object at 0x7f4ac0257160>}\n12543\n{'word': ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.'], 'udtag': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']}\n"
     ]
    }
   ],
   "source": [
    "print(train_data.fields)\n",
    "print(len(train_data))\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(val_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.'], 'udtag': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD.build_vocab(train_data)\n",
    "UD_TAG.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in WORD vocabulary: 19676\n",
      "Unique tokens in CHAR vocabulary: 112\n",
      "Unique tokens in UD_TAG vocabulary: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in WORD vocabulary: {len(WORD.vocab)}\")\n",
    "print(f\"Unique tokens in CHAR vocabulary: {len(CHAR.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'freqs': Counter(), 'itos': ['<unk>', '<pad>', '<bos>', '<eos>', 'e', 't', 'a', 'o', 'n', 'i', 's', 'r', 'h', 'l', 'd', 'u', 'c', 'm', 'y', 'f', 'g', 'w', 'p', '.', 'b', 'v', ',', 'k', 'I', '-', 'T', 'A', '0', 'S', \"'\", 'C', '1', 'E', 'M', 'P', '2', 'x', 'N', 'B', 'W', 'H', 'O', '\"', 'D', 'R', '!', 'L', '/', ':', '3', 'j', 'F', ')', '?', 'G', 'q', '(', '5', 'U', '4', '9', 'J', 'Y', 'z', '6', '7', '8', '_', 'K', 'V', '=', '*', '$', '@', '&', '>', 'Q', '<', ';', 'Z', '’', 'X', '#', '+', '%', '[', ']', '“', '”', '|', '~', '`', '‘', '–', '—', '^', '…', '·', '{', '}', 'é', '£', '\\xad', '³', 'Ã', 'á', 'ç'], 'stoi': defaultdict(<function _default_unk_index at 0x1143a20d0>, {'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3, 'e': 4, 't': 5, 'a': 6, 'o': 7, 'n': 8, 'i': 9, 's': 10, 'r': 11, 'h': 12, 'l': 13, 'd': 14, 'u': 15, 'c': 16, 'm': 17, 'y': 18, 'f': 19, 'g': 20, 'w': 21, 'p': 22, '.': 23, 'b': 24, 'v': 25, ',': 26, 'k': 27, 'I': 28, '-': 29, 'T': 30, 'A': 31, '0': 32, 'S': 33, \"'\": 34, 'C': 35, '1': 36, 'E': 37, 'M': 38, 'P': 39, '2': 40, 'x': 41, 'N': 42, 'B': 43, 'W': 44, 'H': 45, 'O': 46, '\"': 47, 'D': 48, 'R': 49, '!': 50, 'L': 51, '/': 52, ':': 53, '3': 54, 'j': 55, 'F': 56, ')': 57, '?': 58, 'G': 59, 'q': 60, '(': 61, '5': 62, 'U': 63, '4': 64, '9': 65, 'J': 66, 'Y': 67, 'z': 68, '6': 69, '7': 70, '8': 71, '_': 72, 'K': 73, 'V': 74, '=': 75, '*': 76, '$': 77, '@': 78, '&': 79, '>': 80, 'Q': 81, '<': 82, ';': 83, 'Z': 84, '’': 85, 'X': 86, '#': 87, '+': 88, '%': 89, '[': 90, ']': 91, '“': 92, '”': 93, '|': 94, '~': 95, '`': 96, '‘': 97, '–': 98, '—': 99, '^': 100, '…': 101, '·': 102, '{': 103, '}': 104, 'é': 105, '£': 106, '\\xad': 107, '³': 108, 'Ã': 109, 'á': 110, 'ç': 111}), 'vectors': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(CHAR.vocab.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<bos>', '<eos>', '.', 'the', ',', 'to', 'and', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(WORD.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x1143a20d0>, {'<bos>': 0, '<eos>': 1, 'NOUN': 2, 'PUNCT': 3, 'VERB': 4, 'PRON': 5, 'ADP': 6, 'DET': 7, 'PROPN': 8, 'ADJ': 9, 'AUX': 10, 'ADV': 11, 'CCONJ': 12, 'PART': 13, 'NUM': 14, 'SCONJ': 15, 'X': 16, 'INTJ': 17, 'SYM': 18})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(UD_TAG.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    repeat=False,\n",
    "    device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(WORD.vocab), len(UD_TAG.vocab))\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=WORD.vocab.stoi['<pad>'])\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "model = model.to(device)\n",
    "loss_function = loss_function.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_accuracy(scores, targets, lengths):\n",
    "    _, predict = torch.max(scores,1)\n",
    "    batch_len = lengths.max()\n",
    "    mask = torch.Tensor([[0] + [1 for i in range(l-2)] + [0 for i in range(batch_len - l + 1)] for l in lengths])\n",
    "    mask = mask.permute(1, 0).reshape(-1)\n",
    "    total = sum(mask)\n",
    "    correct = predict == targets\n",
    "    correct = correct.type(torch.FloatTensor)\n",
    "    masked_correct = mask * correct\n",
    "    acc = masked_correct.sum() / total\n",
    "    # print(predict)\n",
    "    # print(targets)\n",
    "    # print(total, correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "  \n",
    "    for i, batch in enumerate(iterator):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        # model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Run our forward pass.\n",
    "        inputs, lengths = batch.word\n",
    "        predictions = model(inputs)\n",
    "        predictions = predictions.reshape(-1, predictions.size()[-1])\n",
    "        labels = batch.udtag.reshape(-1)\n",
    "\n",
    "        # Step 3. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = criterion(predictions, labels)\n",
    "        acc = sequence_accuracy(predictions, labels, lengths)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        # if i % 10 == 0:\n",
    "        #     print(f'| Batch: {i:02} | Batch Loss: {loss:.3f} | Batch Acc: {acc*100:.2f}%')\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            # model.hidden = model.init_hidden()\n",
    "            inputs, lengths = batch.word\n",
    "            predictions = model(inputs)\n",
    "            predictions = predictions.reshape(-1, predictions.size()[-1])\n",
    "            labels = batch.udtag.reshape(-1)\n",
    "            # print(predictions.size(), labels.size())\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = sequence_accuracy(predictions, labels, lengths)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kairit/.pyenv/versions/my-virtual-env-3.6.2/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/Users/kairit/.pyenv/versions/my-virtual-env-3.6.2/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 2.071 | Train Acc: 34.63% | Val. Loss: 1.540 | Val. Acc: 45.63% |\n",
      "| Epoch: 02 | Train Loss: 1.443 | Train Acc: 53.80% | Val. Loss: 1.220 | Val. Acc: 56.02% |\n",
      "| Epoch: 03 | Train Loss: 1.190 | Train Acc: 60.55% | Val. Loss: 1.060 | Val. Acc: 59.99% |\n",
      "| Epoch: 04 | Train Loss: 1.048 | Train Acc: 64.09% | Val. Loss: 0.958 | Val. Acc: 63.22% |\n",
      "| Epoch: 05 | Train Loss: 0.943 | Train Acc: 67.03% | Val. Loss: 0.885 | Val. Acc: 65.59% |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_function)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_function)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtual-env-3.6.2",
   "language": "python",
   "name": "my-virtual-env-3.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
